{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333ae546d607a744",
   "metadata": {},
   "source": [
    "# Workshop: Building an Information Retrieval System for Podcast Episodes\n",
    "\n",
    "## Objective:\n",
    "Create an Information Retrieval (IR) system that processes a dataset of podcast transcripts and, given a query, returns the episodes where the host and guest discuss the query topic. Use TF-IDF and BERT for vector space representation and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6be1fd3",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1: Import Libraries\n",
    "Import necessary libraries for data handling, text processing, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec955cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Geovanny\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Geovanny\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gensim.downloader as api\n",
    "from transformers import BertTokenizer, TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc466e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import kaggle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c89088",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset\n",
    "\n",
    "Load the dataset of podcast transcripts.\n",
    "\n",
    "Find the dataset in: https://www.kaggle.com/datasets/rajneesh231/lex-fridman-podcast-transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce235e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "postcast_df = pd.read_csv('data/podcastdata_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7073a63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id            guest                    title  \\\n",
      "0   1      Max Tegmark                 Life 3.0   \n",
      "1   2    Christof Koch            Consciousness   \n",
      "2   3    Steven Pinker  AI in the Age of Reason   \n",
      "3   4    Yoshua Bengio            Deep Learning   \n",
      "4   5  Vladimir Vapnik     Statistical Learning   \n",
      "\n",
      "                                                text  \n",
      "0  As part of MIT course 6S099, Artificial Genera...  \n",
      "1  As part of MIT course 6S099 on artificial gene...  \n",
      "2  You've studied the human mind, cognition, lang...  \n",
      "3  What difference between biological neural netw...  \n",
      "4  The following is a conversation with Vladimir ...  \n"
     ]
    }
   ],
   "source": [
    "print(postcast_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0fe8da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      As part of MIT course 6S099, Artificial Genera...\n",
       "1      As part of MIT course 6S099 on artificial gene...\n",
       "2      You've studied the human mind, cognition, lang...\n",
       "3      What difference between biological neural netw...\n",
       "4      The following is a conversation with Vladimir ...\n",
       "                             ...                        \n",
       "314    By the time he gets to 2045, we'll be able to ...\n",
       "315    there's a broader question here, right? As we ...\n",
       "316    Once this whole thing falls apart and we are c...\n",
       "317    you could be the seventh best player in the wh...\n",
       "318    turns out that if you train a planarian and th...\n",
       "Name: text, Length: 319, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = postcast_df['text']\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1183c2a6",
   "metadata": {},
   "source": [
    "### Step 3: Text Preprocessing\n",
    "\n",
    "You know what to do ;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e498c6",
   "metadata": {},
   "source": [
    "Bert processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c71200b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Geovanny\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d453a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bert_embeddings(texts):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors='tf', padding=True, truncation=True)\n",
    "        outputs = model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state[:, 0, :])  # Use [CLS] token representation\n",
    "    return np.array(embeddings).transpose(0,2,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b55704",
   "metadata": {},
   "source": [
    "TF-IDF PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "994f83e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete puntuacion\n",
    "#stop words\n",
    "corpus_nopunct = []\n",
    "for doc in corpus: \n",
    "    corpus_nopunct.append(doc.lower().translate(str.maketrans('', '', string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04d9bda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id            guest                    title  \\\n",
      "0   1      Max Tegmark                 Life 3.0   \n",
      "1   2    Christof Koch            Consciousness   \n",
      "2   3    Steven Pinker  AI in the Age of Reason   \n",
      "3   4    Yoshua Bengio            Deep Learning   \n",
      "4   5  Vladimir Vapnik     Statistical Learning   \n",
      "\n",
      "                                                text  \\\n",
      "0  As part of MIT course 6S099, Artificial Genera...   \n",
      "1  As part of MIT course 6S099 on artificial gene...   \n",
      "2  You've studied the human mind, cognition, lang...   \n",
      "3  What difference between biological neural netw...   \n",
      "4  The following is a conversation with Vladimir ...   \n",
      "\n",
      "                                        text_nopunct  \n",
      "0  as part of mit course 6s099 artificial general...  \n",
      "1  as part of mit course 6s099 on artificial gene...  \n",
      "2  youve studied the human mind cognition languag...  \n",
      "3  what difference between biological neural netw...  \n",
      "4  the following is a conversation with vladimir ...  \n"
     ]
    }
   ],
   "source": [
    "postcast_df['text_nopunct']=corpus_nopunct\n",
    "print(postcast_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f76d548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Geovanny\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Descargar el recurso stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Cargar las stopwords\n",
    "stopw = set(stopwords.words('english'))\n",
    "print(len(stopw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1d3c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682db53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830f85a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5097e2ff",
   "metadata": {},
   "source": [
    "\n",
    "###  Step 4: Vector Space Representation - TF-IDF\n",
    "\n",
    "Create TF-IDF vector representations of the transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8debbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e77d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cadba27d",
   "metadata": {},
   "source": [
    "### Step 5: Vector Space Representation - BERT\n",
    "\n",
    "Create BERT vector representations of the transcripts using a pre-trained BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a776f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embeddings = generate_bert_embeddings(corpus[:10])\n",
    "print(\"BERT Embeddings:\", bert_embeddings)\n",
    "print(\"Bert Shape:\", bert_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822ac1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8173e117",
   "metadata": {},
   "source": [
    "### Step 6: Query Processing\n",
    "\n",
    "Define a function to process the query and compute similarity scores using both TF-IDF and BERT embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09da40d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5288d7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab49197f",
   "metadata": {},
   "source": [
    "\n",
    "### Step 7: Retrieve and Compare Results\n",
    "\n",
    "Define a function to retrieve the top results based on similarity scores for both TF-IDF and BERT representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca07b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb34fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7b9e796",
   "metadata": {},
   "source": [
    "### Step 8: Test the IR System\n",
    "\n",
    "Test the system with a sample query.\n",
    "\n",
    "Retrieve and display the top results using both TF-IDF and BERT representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048b975e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db154c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9ef4647",
   "metadata": {},
   "source": [
    "### Step 9: Compare Results\n",
    "\n",
    "Analyze and compare the results obtained from TF-IDF and BERT representations.\n",
    "\n",
    "Discuss the differences, strengths, and weaknesses of each method based on the retrieval results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a240d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6c4da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48d4d3ee",
   "metadata": {},
   "source": [
    "\n",
    "## Instructions:\n",
    "\n",
    "* Follow the steps outlined above to implement the IR system.\n",
    "* Run the provided code snippets to understand how each part of the system works.\n",
    "* Test the system with various queries to observe the results from both TF-IDF and BERT representations.\n",
    "* Compare and analyze the results. Discuss the pros and cons of each method.\n",
    "* Document your findings and any improvements you make to the system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
